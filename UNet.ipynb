{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.models import UNet\n",
    "\n",
    "unet = UNet(3)\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRIVE\n",
    "\n",
    "## Read image names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_drive = \"/home/augusto/tmp/datasets/drive/training/\"\n",
    "dir_img = dir_drive + \"images/\"\n",
    "dir_seg = dir_drive + \"1st_manual/\"\n",
    "dir_test = \"/home/augusto/tmp/datasets/drive/test/\"\n",
    "dir_test_img = dir_test + \"images/\"\n",
    "dir_test_seg = dir_test + \"1st_manual/\"\n",
    "\n",
    "with open(dir_drive + 'train.txt') as f:\n",
    "    x = f.read().splitlines()\n",
    "imgs = np.array(x)\n",
    "\n",
    "with open(dir_drive + 'val.txt') as f:\n",
    "    x = f.read().splitlines()\n",
    "val_imgs = np.array(x)\n",
    "\n",
    "with open(dir_test + 'test.txt') as f:\n",
    "    x = f.read().splitlines()\n",
    "test_imgs = np.array(x)\n",
    "\n",
    "print(imgs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "gt = []\n",
    "for line in imgs:\n",
    "    names = line.split(' ')\n",
    "    images.append(m.imread(dir_img + names[0]))\n",
    "    gt.append(m.imread(dir_seg + names[1]))\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 32\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i, img in enumerate(images):\n",
    "    seg_img = gt[i]\n",
    "    X_train.append(extract_patches(img, (patch_size, patch_size)))\n",
    "    y_patches = to_categorical(extract_patches(seg_img, (patch_size,patch_size)))\n",
    "    y_train.append(y_patches)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(\"original image\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    ax.imshow(seg_img, cmap='gray')\n",
    "    ax.set_title('ground truth')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train = np.reshape(X_train, (-1, patch_size,patch_size,3))\n",
    "y_train = np.array(y_train)\n",
    "y_train = np.reshape(y_train, (-1, patch_size, patch_size,2))\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "for line in val_imgs:\n",
    "    names = line.split(' ')\n",
    "    val_img = m.imread(dir_img + names[0])\n",
    "    val_seg = m.imread(dir_seg + names[1])\n",
    "    X_val.append(extract_patches(val_img, (patch_size, patch_size)))\n",
    "    y_patches = to_categorical(extract_patches(val_seg, (patch_size,patch_size)))\n",
    "    y_val.append(y_patches)\n",
    "    \n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_val = np.reshape(X_val, (-1, patch_size, patch_size, 3))\n",
    "y_val = np.reshape(y_val, (-1, patch_size, patch_size, 2))\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "fig = plt.figure(figsize=(5,10))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.imshow(X_train[n][:,:])\n",
    "ax.set_title('img')\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.imshow(y_train[n][:,:,1], cmap='gray')\n",
    "ax.set_title('gt')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-4)\n",
    "\n",
    "unet.compile(loss='binary_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights/unet_drive.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unet.fit(X_train, y_train,\n",
    "#           validation_data=(X_val, y_val),\n",
    "#           epochs=60, batch_size=8,\n",
    "#           verbose=2,\n",
    "#           callbacks=[checkpoint])\n",
    "\n",
    "# unet.save('models/unet_drive.h5')\n",
    "\n",
    "unet = load_model('models/unet_drive.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for line in test_imgs:\n",
    "    names = line.split()\n",
    "    test_img = m.imread(dir_test_img + names[0])\n",
    "    test_seg = m.imread(dir_test_seg + names[1])\n",
    "    X_test.append(test_img)\n",
    "    y_ing = to_categorical(np.array([test_seg]))\n",
    "    y_test.append(y_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "y_test = np.squeeze(y_test)\n",
    "X_test = np.array(X_test)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = unet.predict(X_test[:10,:,:-1,:])\n",
    "y_pred2 = unet.predict(X_test[10:,:,:-1,:])\n",
    "y_pred = np.concatenate((y_pred, y_pred2),axis=0)\n",
    "y_predi = np.argmax(y_pred, axis=3)\n",
    "y_testi = np.argmax(y_test[:,:,:-1,:], axis=3)\n",
    "print(y_testi.shape,y_predi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shape = (584, 565)\n",
    "n_classes= 1\n",
    "\n",
    "for i in range(10):\n",
    "    img_is  = X_test[i]\n",
    "    seg = y_predi[i]\n",
    "    segtest = y_testi[i]\n",
    "\n",
    "    fig = plt.figure(figsize=(20,40))    \n",
    "    ax = fig.add_subplot(1,3,1)\n",
    "    ax.imshow(img_is, cmap='gray')\n",
    "    ax.set_title(\"original\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,2)\n",
    "    ax.imshow(seg, cmap='gray')\n",
    "    ax.set_title(\"predicted class\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,3)\n",
    "    ax.imshow(segtest, cmap='gray')\n",
    "    ax.set_title(\"true class\")\n",
    "    plt.show()\n",
    "        \n",
    "#     m.imsave('images/drive/'+str(i)+'_orig.png', img_is)\n",
    "    m.imsave('images/drive/'+str(i)+'_pred_unet.png', seg)\n",
    "#     m.imsave('images/drive/'+str(i)+'_segm.png', segtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rates(pred, gt):\n",
    "    gtp = (gt >= 1).astype(int)\n",
    "    pp = (pred >= 1).astype(int)\n",
    "    gtn = (gt == 0).astype(int)\n",
    "    pn = (pred == 0).astype(int)\n",
    "   \n",
    "    TP = (gtp*pp).sum()\n",
    "    TN = (gtn*pn).sum()\n",
    "    FP = (gtn*pp).sum()\n",
    "    FN = (gtp*pn).sum()   \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def precision(pred, gt):\n",
    "    TP, TN, FP, FN = calc_rates(pred, gt)\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "\n",
    "def recall(pred, gt):\n",
    "    TP, TN, FP, FN = calc_rates(pred, gt)\n",
    "    return TP/(TP+FN)\n",
    "\n",
    "\n",
    "def FM(prediction, ground_truth):\n",
    "    P = precision(prediction, ground_truth)\n",
    "    R = recall(prediction, ground_truth)\n",
    "    F = (2*P*R)/(P+R)\n",
    "    return F\n",
    "\n",
    "test_gt = y_testi\n",
    "P = precision(y_predi, test_gt)\n",
    "R = recall(y_predi, test_gt)\n",
    "F = FM(y_predi, test_gt)\n",
    "\n",
    "print(P, R, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIBCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_dibco = \"/home/augusto/tmp/scratch/DIBCO/\"\n",
    "\n",
    "with open(dir_dibco + 'train.txt') as f:\n",
    "    x = f.read().splitlines()\n",
    "imgs = np.array(x)\n",
    "\n",
    "with open(dir_dibco + 'val.txt') as f:\n",
    "    x = f.read().splitlines()\n",
    "val_imgs = np.array(x)\n",
    "\n",
    "with open(dir_dibco + 'test.txt') as f:\n",
    "    x = f.read().splitlines()\n",
    "test_imgs = np.array(x)\n",
    "\n",
    "print(imgs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "gt = []\n",
    "for line in imgs:\n",
    "    names = line.split()\n",
    "    images.append(m.imread(dir_dibco + names[0], mode='RGB'))\n",
    "    gt.append(m.imread(dir_dibco + names[1], mode='L'))\n",
    "images = np.array(images)\n",
    "gt = np.array(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patch_size = 32\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i, img in enumerate(images):\n",
    "    seg_img = gt[i]\n",
    "    X_train.append(extract_patches(img, (patch_size, patch_size)))\n",
    "    y_patches = to_categorical(extract_patches(seg_img, (patch_size, patch_size)))\n",
    "    y_train.append(y_patches)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(\"original image\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    ax.imshow(seg_img, cmap='gray')\n",
    "    ax.set_title('ground truth')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_train = np.reshape(X_train, (-1, patch_size,patch_size,3))\n",
    "y_train = np.array(y_train)\n",
    "y_train = np.vstack(y_train)\n",
    "y_train = np.reshape(y_train, (-1, patch_size, patch_size,2))\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "for line in val_imgs:\n",
    "    names = line.split()\n",
    "    val_img = m.imread(dir_dibco + names[0], mode='RGB')\n",
    "    val_seg = m.imread(dir_dibco + names[1], mode='L')\n",
    "    X_val.append(extract_patches(val_img, (patch_size, patch_size)))\n",
    "    y_patches = to_categorical(extract_patches(val_seg, (patch_size,patch_size)))\n",
    "    y_val.append(y_patches)\n",
    "    \n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_val = np.vstack(X_val)\n",
    "X_val = np.reshape(X_val, (-1, patch_size, patch_size, 3))\n",
    "y_val = np.vstack(y_val)\n",
    "y_val = np.reshape(y_val, (-1, patch_size, patch_size, 2))\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 533\n",
    "fig = plt.figure(figsize=(5,10))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.imshow(X_train[n][:,:])\n",
    "ax.set_title('img')\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.imshow(y_train[n][:,:,1], cmap='gray')\n",
    "ax.set_title('gt')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-4)\n",
    "\n",
    "unet.compile(loss='binary_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights/unet_dibco.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unet.fit(X_train, y_train,\n",
    "#           validation_data=(X_val, y_val),\n",
    "#           epochs=60, batch_size=32,\n",
    "#           verbose=2,\n",
    "#           callbacks=[checkpoint])\n",
    "\n",
    "# unet.save('models/unet_dibco.h5')\n",
    "\n",
    "unet = load_model('models/unet_dibco.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crop(img, mult):\n",
    "    H, W, *c = img.shape\n",
    "    h = H - H%mult\n",
    "    w = W - W%mult\n",
    "    return img[:h,:w]\n",
    "    \n",
    "X_test = []\n",
    "y_test = []\n",
    "for line in test_imgs:\n",
    "    names = line.split()\n",
    "    test_img = m.imread(dir_dibco + names[0], mode='RGB')\n",
    "    test_seg = m.imread(dir_dibco + names[1], mode='L')\n",
    "    X_test.append(crop(test_img, 4))\n",
    "    y_ing = to_categorical(np.array([test_seg]))\n",
    "    y_test.append(crop(y_ing[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predi = []\n",
    "y_testi = []\n",
    "for i, ing in enumerate(X_test):\n",
    "    y_pred = unet.predict(np.asarray([ing]))\n",
    "    y_predi.append(np.argmax(y_pred, axis=3))\n",
    "    y_testi.append(np.argmax(y_test[i], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ing in enumerate(y_predi):\n",
    "    gtn = (y_testi[i] == 1).astype(int)\n",
    "    pn = (ing[0] == 1).astype(int)\n",
    "    gtp = (y_testi[i] == 0).astype(int)\n",
    "    pp = (ing[0] == 0).astype(int)\n",
    "\n",
    "TP = (gtp*pp).sum()\n",
    "TN = (gtn*pn).sum()\n",
    "FP = (gtn*pp).sum()\n",
    "FN = (gtp*pn).sum()\n",
    "\n",
    "Precision = TP/(TP+FP)\n",
    "Sensitivity = TP/(TP+FN)\n",
    "print(Precision, Sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    img_is  = X_test[i]\n",
    "    seg = y_predi[i][0]\n",
    "    segtest = y_testi[i]\n",
    "\n",
    "    fig = plt.figure(figsize=(20,40))    \n",
    "    ax = fig.add_subplot(1,3,1)\n",
    "    ax.imshow(img_is, cmap='gray')\n",
    "    ax.set_title(\"original\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,2)\n",
    "    ax.imshow(seg, cmap='gray')\n",
    "    ax.set_title(\"predicted class\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,3)\n",
    "    ax.imshow(segtest, cmap='gray')\n",
    "    ax.set_title(\"true class\")\n",
    "    plt.show()\n",
    "    \n",
    "#     m.imsave('images/dibco/'+str(i)+'_orig.png', img_is)\n",
    "    m.imsave('images/dibco/'+str(i)+'_pred_unet.png', seg)\n",
    "#     m.imsave('images/dibco/'+str(i)+'_segm.png', segtest)\n",
    "    \n",
    "    print(img_is.shape, seg.shape, segtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# INRIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_inria = \"/home/augusto/tmp/scratch/INRIA/\"\n",
    "dir_img = dir_inria + \"images/patches/\"\n",
    "dir_seg = dir_inria + \"gt/patches/\"\n",
    "dir_test_img = dir_inria + \"images/\"\n",
    "dir_test_seg = dir_inria + \"gt/\"\n",
    "\n",
    "with open(dir_inria + 'train.txt') as f:\n",
    "    x = f.read().splitlines()\n",
    "imgs = np.array(x)\n",
    "\n",
    "with open(dir_inria + 'val.txt') as f:\n",
    "    x = f.read().splitlines()\n",
    "val_imgs = np.array(x)\n",
    "\n",
    "with open(dir_inria + 'test.txt') as f:\n",
    "    x = f.read().splitlines()\n",
    "test_imgs = np.array(x)\n",
    "\n",
    "print(imgs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "gt = []\n",
    "for line in imgs:\n",
    "    names = line.split()\n",
    "    images.append(m.imread(dir_img + names[0], mode='RGB'))\n",
    "    gt.append(m.imread(dir_seg + names[1], mode='L'))\n",
    "images = np.array(images)\n",
    "gt = np.array(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patch_size = 48\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i, img in enumerate(images):\n",
    "    seg_img = gt[i]\n",
    "    X_train.append(extract_patches(img, (patch_size, patch_size)))\n",
    "    y_patches = to_categorical(extract_patches(seg_img, (patch_size, patch_size)))\n",
    "    y_train.append(y_patches)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(\"original image\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    ax.imshow(seg_img, cmap='gray')\n",
    "    ax.set_title('ground truth')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_train = np.reshape(X_train, (-1, patch_size,patch_size,3))\n",
    "y_train = np.array(y_train)\n",
    "y_train = np.vstack(y_train)\n",
    "y_train = np.reshape(y_train, (-1, patch_size, patch_size,2))\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "for line in val_imgs:\n",
    "    names = line.split()\n",
    "    val_img = m.imread(dir_img + names[0], mode='RGB')\n",
    "    val_seg = m.imread(dir_seg + names[1], mode='L')\n",
    "    X_val.append(extract_patches(val_img, (patch_size, patch_size)))\n",
    "    y_patches = to_categorical(extract_patches(val_seg, (patch_size,patch_size)))\n",
    "    y_val.append(y_patches)\n",
    "    \n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_val = np.vstack(X_val)\n",
    "X_val = np.reshape(X_val, (-1, patch_size, patch_size, 3))\n",
    "y_val = np.vstack(y_val)\n",
    "y_val = np.reshape(y_val, (-1, patch_size, patch_size, 2))\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if patch and ground truth matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 1353\n",
    "fig = plt.figure(figsize=(5,10))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.imshow(X_train[n][:,:])\n",
    "ax.set_title('img')\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.imshow(y_train[n][:,:,1], cmap='gray')\n",
    "ax.set_title('gt')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-4)\n",
    "\n",
    "unet.compile(loss='binary_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights/unet_inria.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unet.load_weights('weights/unet_inria.hdf5')\n",
    "\n",
    "# unet.fit(X_train, y_train,\n",
    "#           validation_data=(X_val, y_val),\n",
    "#           epochs=60, batch_size=32,\n",
    "#           verbose=2,\n",
    "#           callbacks=[checkpoint])\n",
    "\n",
    "# unet.save('models/unet_inria.h5')\n",
    "\n",
    "unet = load_model('models/unet_dibco.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def crop(img, mult):\n",
    "    H, W, *c = img.shape\n",
    "    h = H - H%mult\n",
    "    w = W - W%mult\n",
    "    return img[:h,:w]\n",
    "    \n",
    "X_test = []\n",
    "y_test = []\n",
    "for line in test_imgs:\n",
    "    names = line.split()\n",
    "    test_img = m.imread(dir_test_img + names[0], mode='RGB')\n",
    "    test_seg = m.imread(dir_test_seg + names[1], mode='L')\n",
    "    X_test.append(crop(test_img, 4))\n",
    "    y_ing = to_categorical(np.array([test_seg]))\n",
    "    y_test.append(crop(y_ing[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predi = []\n",
    "y_testi = []\n",
    "for i, ing in enumerate(X_test):\n",
    "    for k in range(5):\n",
    "        for j in range(5):\n",
    "            y_pred = unet.predict(np.asarray([ing[j*1000:(j+1)*1000,k*1000:(k+1)*1000]]))\n",
    "            y_predi.append(np.argmax(y_pred, axis=3))\n",
    "            y_testi.append(np.argmax(y_test[i], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    img_is  = X_test[i]\n",
    "    seg = y_predi[i][0]\n",
    "    segtest = y_testi[i]\n",
    "\n",
    "    fig = plt.figure(figsize=(20,40))    \n",
    "    ax = fig.add_subplot(1,3,1)\n",
    "    ax.imshow(img_is, cmap='gray')\n",
    "    ax.set_title(\"original\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,2)\n",
    "    ax.imshow(seg, cmap='gray')\n",
    "    ax.set_title(\"predicted class\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,3)\n",
    "    ax.imshow(segtest, cmap='gray')\n",
    "    ax.set_title(\"true class\")\n",
    "    plt.show()\n",
    "    \n",
    "#     m.imsave('images/inria/'+str(i)+'_orig.png', img_is)\n",
    "    m.imsave('images/inria/'+str(i)+'_pred_unet.png', seg)\n",
    "#     m.imsave('images/inria/'+str(i)+'_segm.png', segtest)\n",
    "    \n",
    "    print(img_is.shape, seg.shape, segtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
